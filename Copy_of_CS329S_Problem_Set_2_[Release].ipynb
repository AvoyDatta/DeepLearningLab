{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of CS329S Problem Set 2 [Release].ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "344440daf7e744729954eaefc4ca1228": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dee5cb79a52e49928e225a0111ca1400",
              "IPY_MODEL_0bb5aa1ce8044cbd983dc0e4263d5026"
            ],
            "layout": "IPY_MODEL_faabfb8b8db246a0a15812e73e8d4d6d"
          }
        },
        "dee5cb79a52e49928e225a0111ca1400": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "Downloading: 100%",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f597215a06d495d8282eeb21aea21f3",
            "max": 485,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_88fe1e39aec444319b6e4298177e6416",
            "value": 485
          }
        },
        "0bb5aa1ce8044cbd983dc0e4263d5026": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4e6064b114a4802af32c0e35f1f7744",
            "placeholder": "​",
            "style": "IPY_MODEL_0cadb7c27a30483dba18dbfd4d5ce155",
            "value": " 485/485 [00:00&lt;00:00, 9.82kB/s]"
          }
        },
        "faabfb8b8db246a0a15812e73e8d4d6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f597215a06d495d8282eeb21aea21f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88fe1e39aec444319b6e4298177e6416": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        },
        "b4e6064b114a4802af32c0e35f1f7744": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0cadb7c27a30483dba18dbfd4d5ce155": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6e0e0965ba1247129a626fcb9e2728ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2797f63ed1304f39b2689000355ab1ac",
              "IPY_MODEL_30c4f78019994783b3f3f3dcdbd21298"
            ],
            "layout": "IPY_MODEL_7b8047f206204f5c862beeb5923a7556"
          }
        },
        "2797f63ed1304f39b2689000355ab1ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "Downloading: 100%",
            "description_tooltip": null,
            "layout": "IPY_MODEL_befd49d6700e4d849675f886fe37ac2a",
            "max": 267845150,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_26aae840f93740589e59521b467824b8",
            "value": 267845150
          }
        },
        "30c4f78019994783b3f3f3dcdbd21298": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2f894bad5204f8fb3a72c7325edc4fb",
            "placeholder": "​",
            "style": "IPY_MODEL_a859faac9ab347fa8b0d4a88ecf3b13d",
            "value": " 268M/268M [00:06&lt;00:00, 43.0MB/s]"
          }
        },
        "7b8047f206204f5c862beeb5923a7556": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "befd49d6700e4d849675f886fe37ac2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26aae840f93740589e59521b467824b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        },
        "d2f894bad5204f8fb3a72c7325edc4fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a859faac9ab347fa8b0d4a88ecf3b13d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AvoyDatta/DeepLearningLab/blob/master/Copy_of_CS329S_Problem_Set_2_%5BRelease%5D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipOzcEPc58Y-"
      },
      "source": [
        "# CS329S Problem Set 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KO2euNRD5EyC"
      },
      "source": [
        "# Overview\n",
        "\n",
        "In the last assignment, we’ve tested some public ML systems. In this assignment, we’ll familiarize ourselves with how to train and evaluate models.\n",
        "\n",
        "We'll be using two commercial APIs: [HuggingFace API](https://huggingface.co/) and [OpenAI API](https://beta.openai.com/).\n",
        "\n",
        "## OpenAI API\n",
        "\n",
        "You should have received an invite to access OpenAI API by now. Please let us know if you haven’t.\n",
        "\n",
        "## Optional access to HuggingFace’s paid inference API\n",
        "\n",
        "The class has a startup plan on HuggingFace. To access the class’s benefits -- e.g. running inference using their GPUs instead of using your own GPU credits -- please create an account and ask to join [Stanford CS 329S organization](https://huggingface.co/stanford-cs329s). We’ll add you in. Don’t wait until the last minute to join because we might not be able to accept your requests in time!\n",
        "\n",
        "We emphasize that joining the organization is optional: we have found the models to work fine running on the GPUs associated with Google Colab, so if you would rather run your models on Colab’s GPUs without the CS329S HuggingFace organization, it should not limit your ability to complete the assignment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSss-xxY6EJJ"
      },
      "source": [
        "# Submission\n",
        "1. Click ***File > Save a Copy in Drive*** to save your own copy of the document to work in and submit.\n",
        "2. Please answer all the problems from this problem set in your Colab notebook.\n",
        "3. Submit **both** `ps2.ipynb` notebook file and `ps2.pdf` to Gradescope. \n",
        "  - To download the `ps2.ipynb`: File > Download .ipynb\n",
        "  - To download the `ps2.pdf`: File > Print\n",
        "\n",
        "\n",
        "**This assignment is meaty. Start early!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hq906xs8LVg"
      },
      "source": [
        "\n",
        "**Tip**: You can use the colab GPU for this by selecting:\n",
        "\n",
        "> **Runtime**   →   **Change runtime type**   →   **Hardware Accelerator: GPU**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKifPThZ521X"
      },
      "source": [
        "# Part I. Understanding pretrained models\n",
        "\n",
        "Some of the HuggingFace modules that you might find useful for this assignment.\n",
        "- [`load_dataset`](https://huggingface.co/docs/datasets/loading_datasets.html)\n",
        "- [`pipelines`](https://huggingface.co/transformers/main_classes/pipelines.html)\n",
        "- [`Trainer`](https://huggingface.co/transformers/main_classes/trainer.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4C8yidYS-rJ8"
      },
      "source": [
        "Run the following cells to set up the necessary prerequisites. Feel free to modify the cells to import any module you need."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3eTwI3f77zP",
        "outputId": "9b662b48-f281-4d02-edfa-3c93e5be5877"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')\r\n",
        "%cd '/content/drive/MyDrive/cs329s_ps2'\r\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/cs329s_ps2\n",
            "aclImdb  aclImdb_v1.tar.gz  logs  my_model.h5  runs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRlbmlaZDmMZ",
        "outputId": "46f104a4-00c2-4570-c9d8-4258447169b5"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Feb 13 06:23:44 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.39       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   50C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5D27OZaf-mfP",
        "outputId": "928e9134-d8fe-41fd-fcd2-260e9ea9936d"
      },
      "source": [
        "!pip install -q transformers\n",
        "!pip install -q datasets\n",
        "!pip install nltk"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.8MB 26.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 890kB 46.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.2MB 49.1MB/s \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 163kB 17.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 20.7MB 6.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 245kB 45.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrGpHY_3nFZw",
        "outputId": "d753dd34-ca75-4a67-8133-dec3a1441033"
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "from datasets import load_dataset\n",
        "from datasets import load_metric\n",
        "from transformers import pipeline\n",
        "from transformers import DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
        "\n",
        "from sklearn.calibration import calibration_curve\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XchTx16l8FZW"
      },
      "source": [
        "## Problem 1: Setup\n",
        "\n",
        "We’ll examine pretrained language models’ performance for the task of sentiment analysis with two classes. For Problem 1 and Problem 2 of this assignment, you’ll need to pick the following:\n",
        "\n",
        "- **Fine-tuned model**: choose one pretrained language model that has been fine-tuned on the IMDB dataset from the [HuggingFace Model Hub](https://huggingface.co/models). You can see the list of available models trained on IMDB [here](https://huggingface.co/models?search=imdb). Examples:\n",
        "    - `roberta-base-imdb` is `robert-base` that has been fine-tuned on the IMDB dataset.\n",
        "    - `distilbert-base-uncased-imdb` is `distilbert-base-uncased` that has been fine-tuned on the IMDB dataset.\n",
        "\n",
        "- **Out-of-distribution dataset**: pick a **binary label** sentiment analysis dataset that IS NOT IMDB from HuggingFace Datasets interface (some of them have more than two labels, so make sure you pick one with binary labels!). You can find the list of sentiment analysis tasks [here](https://huggingface.co/datasets?filter=task_ids:sentiment-classification).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLbLPJJc8M5w"
      },
      "source": [
        "### 1.1 Understanding your fine-tuned model [5 points]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMUHo5nr9tM_"
      },
      "source": [
        "#### a. (1 point) What fine-tuned model did you choose? What’s its pretrained LM counterpart?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcxVDiFR_HKA"
      },
      "source": [
        "**Answer**:\n",
        "\n",
        "distilbert-base-uncased-imdb\n",
        "\n",
        "The underlying LM is Distilbert (https://arxiv.org/abs/1910.01108) from HuggingFace. The co-authors trained a smaller version of BERT using knowledge distillation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPBzeuBF-QBz"
      },
      "source": [
        "#### b. (1 point) Is your model cased or uncased? Why did you choose that?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5B4eqoV_MmD"
      },
      "source": [
        "**Answer**:\n",
        "\n",
        "Uncased. When it comes to IMDB reviews, the labels should be case-invariant."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3509RkD-ghk"
      },
      "source": [
        "#### c. (3 points) What is the number of parameters in your model? You can find this number either from the original paper or write code to count its number of parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132,
          "referenced_widgets": [
            "344440daf7e744729954eaefc4ca1228",
            "dee5cb79a52e49928e225a0111ca1400",
            "0bb5aa1ce8044cbd983dc0e4263d5026",
            "faabfb8b8db246a0a15812e73e8d4d6d",
            "9f597215a06d495d8282eeb21aea21f3",
            "88fe1e39aec444319b6e4298177e6416",
            "b4e6064b114a4802af32c0e35f1f7744",
            "0cadb7c27a30483dba18dbfd4d5ce155",
            "6e0e0965ba1247129a626fcb9e2728ae",
            "2797f63ed1304f39b2689000355ab1ac",
            "30c4f78019994783b3f3f3dcdbd21298",
            "7b8047f206204f5c862beeb5923a7556",
            "befd49d6700e4d849675f886fe37ac2a",
            "26aae840f93740589e59521b467824b8",
            "d2f894bad5204f8fb3a72c7325edc4fb",
            "a859faac9ab347fa8b0d4a88ecf3b13d"
          ]
        },
        "id": "V0GmVa2Dc64c",
        "outputId": "b59a5f52-f5c1-470b-dff7-93d6c44a7b9b"
      },
      "source": [
        "################## (OPTIONAL) YOUR CODE HERE ##################\n",
        "# Find the number of parameters in your model\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "\n",
        "pretrained = AutoModelForSequenceClassification.from_pretrained(\"textattack/distilbert-base-uncased-imdb\")\n",
        "pretrained.num_parameters()\n",
        "###############################################################"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "344440daf7e744729954eaefc4ca1228",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=485.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6e0e0965ba1247129a626fcb9e2728ae",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=267845150.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "66955010"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6re4vEqOHcn"
      },
      "source": [
        "# pretrained.config"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6fdXPA__NSW"
      },
      "source": [
        "**Answer**:\n",
        "\n",
        "As validated above, the DistilBERT model has about **66.96 M params.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQfGlulX_QVa"
      },
      "source": [
        "### 1.2 Understanding the [IMDB dataset](https://ai.stanford.edu/~amaas/data/sentiment/) [3 points]\n",
        "\n",
        "**Tip**: The IMDB dataset can also be explored in the Hugging Face model hub ([IMDb](https://huggingface.co/datasets/imdb)) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9rxPf6KpEmm"
      },
      "source": [
        "**Example: Loading Dataset**\n",
        "\n",
        "The following cell shows how to use the HuggingFace [`Datasets`](https://github.com/huggingface/datasets) library to download and prepare the IMDb dataset. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keZrpp3BcmHV"
      },
      "source": [
        "# dataset = load_dataset(\"imdb\")\n",
        "\n",
        "# dataset\n",
        "# dataset['test'][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYzwSk8IpzMF"
      },
      "source": [
        "**Alternatively**, you can also read in datasets from raw text. Checkout this [tutorial](https://huggingface.co/transformers/custom_datasets.html?highlight=imdb%20rating%20dataset) for more details."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccw761jyqLXf",
        "outputId": "443537ab-9232-48b9-e9c0-88cbce01a56b"
      },
      "source": [
        "! wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "! tar -xf aclImdb_v1.tar.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-02-13 06:25:01--  http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n",
            "Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 84125825 (80M) [application/x-gzip]\n",
            "Saving to: ‘aclImdb_v1.tar.gz.1’\n",
            "\n",
            "aclImdb_v1.tar.gz.1 100%[===================>]  80.23M  25.5MB/s    in 4.2s    \n",
            "\n",
            "2021-02-13 06:25:06 (19.1 MB/s) - ‘aclImdb_v1.tar.gz.1’ saved [84125825/84125825]\n",
            "\n",
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Kl7u461wqUfe",
        "outputId": "a531e50a-0065-496b-db8d-78c54c96612c"
      },
      "source": [
        "from pathlib import Path\n",
        "\n",
        "def read_imdb_split(split_dir):\n",
        "    split_dir = Path(split_dir)\n",
        "    texts = []\n",
        "    labels = []\n",
        "    for label_dir in [\"pos\", \"neg\"]:\n",
        "        for text_file in (split_dir/label_dir).iterdir():\n",
        "            texts.append(text_file.read_text())\n",
        "            labels.append(0 if label_dir is \"neg\" else 1)\n",
        "\n",
        "    return texts, labels\n",
        "\n",
        "train_texts, train_labels = read_imdb_split('aclImdb/train')\n",
        "test_texts, test_labels = read_imdb_split('aclImdb/test')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-1a25e9e1b27c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mtrain_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_imdb_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'aclImdb/train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mtest_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_imdb_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'aclImdb/test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-1a25e9e1b27c>\u001b[0m in \u001b[0;36mread_imdb_split\u001b[0;34m(split_dir)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlabel_dir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"pos\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"neg\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtext_file\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msplit_dir\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlabel_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0mtexts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlabel_dir\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;34m\"neg\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/pathlib.py\u001b[0m in \u001b[0;36mread_text\u001b[0;34m(self, encoding, errors)\u001b[0m\n\u001b[1;32m   1195\u001b[0m         \"\"\"\n\u001b[1;32m   1196\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1197\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrite_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m         \u001b[0;31m# decode input (taking the buffer into account)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PE3E1M5sF-p"
      },
      "source": [
        "                                                ################## (OPTIONAL) YOUR CODE HERE ##################\n",
        "# Feel free to write your own code to import the IMDB dataset.\n",
        "###############################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCkPpd6T_aYW"
      },
      "source": [
        "#### a. (1 point) Plot the reviews' lengths (word count) as a histogram for entire dataset (train + test).\n",
        "\n",
        "- If you need some help generating plots, checkout matplotlib [tutorial](https://matplotlib.org/3.1.1/gallery/statistics/hist.html)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ufh-PqqVrT4S"
      },
      "source": [
        "################## YOUR CODE HERE ##################\n",
        "# Plot the review's lengths\n",
        "\n",
        "all_texts = train_texts + test_texts\n",
        "all_lens = [len(nltk.tokenize.word_tokenize(text)) for text in all_texts]\n",
        "\n",
        "plt.hist(all_lens)\n",
        "plt.xlabel('word counts')\n",
        "plt.show()\n",
        "####################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8S8evC-vBZf7"
      },
      "source": [
        "**Answer**:\n",
        "\n",
        "[YOUR ANSWER HERE]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soruUXU8BKZP"
      },
      "source": [
        "#### b. (1 point) Report the label distribution (number of positive and negative examples) for both the train and test splits."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOaBCvqJsDql",
        "outputId": "fdc3d19e-e49b-4f0c-93f4-df456907459e"
      },
      "source": [
        "################## YOUR CODE HERE ##################\n",
        "# Find the label distributions\n",
        "\n",
        "print(\"### Train ###\")\n",
        "_, cts = np.unique(train_labels, return_counts=True)\n",
        "print(f\"Positive samples: {cts[1]}\")\n",
        "print(f\"Negative samples: {cts[0]}\")\n",
        "\n",
        "\n",
        "print(\"### Test ###\")\n",
        "_, cts = np.unique(test_labels, return_counts=True)\n",
        "print(f\"Positive samples: {cts[1]}\")\n",
        "print(f\"Negative samples: {cts[0]}\")\n",
        "####################################################"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "### Train ###\n",
            "Positive samples: 8622\n",
            "Negative samples: 12500\n",
            "### Test ###\n",
            "Positive samples: 12500\n",
            "Negative samples: 12500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsKx9m1mBaoK"
      },
      "source": [
        "**Answer**:\n",
        "\n",
        "### Train ###\n",
        "\n",
        "Positive samples: 12500\n",
        "Negative samples: 12500\n",
        "\n",
        "\n",
        "### Test ###\n",
        "Positive samples: 12500\n",
        "Negative samples: 12500"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1786d5r7BOmU"
      },
      "source": [
        "#### c. (1 point) What evaluation metric(s) would be appropriate for this dataset? Why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkPr5BdqBbUE"
      },
      "source": [
        "**Answer**:\n",
        "\n",
        "The train and test splits are *perfectly* balanced. Thus, top-1 accuracy would be an appropriate metric. F-1 score would also be a valid metric if we want to balance the effects of false positives vs false negatives. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDWfk7-XBw1L"
      },
      "source": [
        "### 1.3 Understanding the out-of-distribution dataset [3 points]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUsipGHtB4wm"
      },
      "source": [
        "#### a. (1 point) What's the name of your out-of-distribution dataset? Include a link. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HaUJLAhyCgpl"
      },
      "source": [
        "**Answer**:\n",
        "\n",
        "Name: amazon_polarity\n",
        "Link: https://huggingface.co/datasets/amazon_polarity\n",
        "\n",
        "\"The data span a period of 18 years, including ~35 million reviews up to March 2013. Reviews include product and user information, ratings, and a plaintext review.\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIYitK61CCk-"
      },
      "source": [
        "#### b. (1 point) Describe your dataset, including its splits, its columns, and their statistics. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKsphvsDs_SG"
      },
      "source": [
        "################## YOUR CODE HERE ##################\n",
        "# Load your data and find your dataset's statistics\n",
        "ood = load_dataset(\"amazon_polarity\")\n",
        "ood\n",
        "\n",
        "####################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "om5K9IegChbC"
      },
      "source": [
        "**Answer**:\n",
        "\n",
        "    train: Dataset({\n",
        "        features: ['label', 'title', 'content'],\n",
        "        num_rows: 3600000\n",
        "    })\n",
        "    test: Dataset({\n",
        "        features: ['label', 'title', 'content'],\n",
        "        num_rows: 400000\n",
        "    })\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edC6E0IiCZYf"
      },
      "source": [
        "#### c. (1 point) Report the label distribution (number of positive and negative examples) for both the train and test splits."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i27DX5metFnQ"
      },
      "source": [
        "################## YOUR CODE HERE ##################\n",
        "# Plot the label distribution\n",
        "####################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5_VuqTFCh8y"
      },
      "source": [
        "**Answer**:\n",
        "\n",
        "[YOUR ANSWER HERE]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzBTedu9DsyZ"
      },
      "source": [
        "## Problem 2. Training from scratch v.s. pretrained-model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOeCZPU-F267"
      },
      "source": [
        "### 2.1 Train a sentiment analysis model from scratch [10 points with 5 extra credit]\n",
        "\n",
        "Use any framework (e.g. sklearn, PyTorch, Keras, TensorFlow) and any architecture (e.g. Logistic Regression, LSTM, Transformers), train a sentiment analysis model from scratch to get an accuracy of at least 85% on the test split of the IMDB dataset.\n",
        "\n",
        "- **5 extra points if your model’s accuracy is above 90%**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Enl0F3xLngid"
      },
      "source": [
        "### General variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_Hy7llntv7v"
      },
      "source": [
        "# # config = pretrained.config\r\n",
        "# from sklearn.model_selection import train_test_split\r\n",
        "# train_texts, val_texts, train_labels, val_labels = train_test_split(train_texts, train_labels, test_size=.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbRy1_F50vKY"
      },
      "source": [
        "from transformers import DistilBertTokenizerFast\r\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\r\n",
        "\r\n",
        "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\r\n",
        "# val_encodings = tokenizer(val_texts, truncation=True, padding=True)\r\n",
        "test_encodings = tokenizer(test_texts, truncation=True, padding=True)\r\n",
        "\r\n",
        "toy_encodings = tokenizer(train_texts[:100], truncation=True, padding=True)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGX5zo9000TC",
        "outputId": "f2ee9db1-d933-4419-d8c7-1e60ddb46ce3"
      },
      "source": [
        "## Scratch model specific\r\n",
        "\r\n",
        "# Load pretrained model config\r\n",
        "import tensorflow as tf\r\n",
        "from transformers import TFDistilBertForSequenceClassification\r\n",
        "\r\n",
        "pre_tf = TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')\r\n",
        "pre_tf.summary()\r\n",
        "config = pre_tf.config\r\n",
        "\r\n",
        "## Set tf dataset\r\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((\r\n",
        "    dict(train_encodings),\r\n",
        "    train_labels\r\n",
        "))\r\n",
        "# val_dataset = tf.data.Dataset.from_tensor_slices((\r\n",
        "#     dict(val_encodings),\r\n",
        "#     val_labels\r\n",
        "# ))\r\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((\r\n",
        "    dict(test_encodings),\r\n",
        "    test_labels\r\n",
        "))\r\n",
        "\r\n",
        "toy_dataset = tf.data.Dataset.from_tensor_slices((\r\n",
        "    dict(toy_encodings),\r\n",
        "    train_labels[:100]\r\n",
        "))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['vocab_transform', 'activation_13', 'vocab_layer_norm', 'vocab_projector']\n",
            "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier', 'dropout_19', 'pre_classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"tf_distil_bert_for_sequence_classification\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "distilbert (TFDistilBertMain multiple                  66362880  \n",
            "_________________________________________________________________\n",
            "pre_classifier (Dense)       multiple                  590592    \n",
            "_________________________________________________________________\n",
            "classifier (Dense)           multiple                  1538      \n",
            "_________________________________________________________________\n",
            "dropout_19 (Dropout)         multiple                  0         \n",
            "=================================================================\n",
            "Total params: 66,955,010\n",
            "Trainable params: 66,955,010\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwG8RyzP9VvV"
      },
      "source": [
        "# Define callbacks & optimizer\r\n",
        "es = tf.keras.callbacks.EarlyStopping(\r\n",
        "    monitor='val_loss', min_delta=0, patience=1, verbose=1,\r\n",
        "    mode='auto', baseline=None, restore_best_weights=True\r\n",
        ")\r\n",
        "\r\n",
        "ckpt = tf.keras.callbacks.ModelCheckpoint(\r\n",
        "    './best_model.h5', monitor='val_loss', verbose=1, save_best_only=True,\r\n",
        "    save_weights_only=False, mode='auto', save_freq='epoch'\r\n",
        ")\r\n",
        "\r\n",
        "\r\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3OJoux6cGZj",
        "outputId": "979246d1-c380-4c9a-f4e5-35fc1bfdb468"
      },
      "source": [
        "train_dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TensorSliceDataset shapes: ({input_ids: (512,), attention_mask: (512,)}, ()), types: ({input_ids: tf.int32, attention_mask: tf.int32}, tf.int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_xbhJeMcd1-"
      },
      "source": [
        "from transformers import TFDistilBertForSequenceClassification, TFTrainer, TFTrainingArguments\r\n",
        "\r\n",
        "training_args = TFTrainingArguments(\r\n",
        "    output_dir='./results',          # output directory\r\n",
        "    num_train_epochs=3,              # total number of training epochs\r\n",
        "    per_device_train_batch_size=16,  # batch size per device during training\r\n",
        "    per_device_eval_batch_size=64,   # batch size for evaluation\r\n",
        "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\r\n",
        "    weight_decay=0.01,               # strength of weight decay\r\n",
        "    logging_dir='./logs',            # directory for storing logs\r\n",
        "    logging_steps=10,\r\n",
        ")\r\n",
        "\r\n",
        "# with training_args.strategy.scope():\r\n",
        "model = TFDistilBertForSequenceClassification(config=config)\r\n",
        "\r\n",
        "trainer = TFTrainer(\r\n",
        "    model=model,                         # the instantiated 🤗 Transformers model to be trained\r\n",
        "    args=training_args,                  # training arguments, defined above\r\n",
        "    train_dataset=toy_dataset,         # training dataset\r\n",
        "    eval_dataset=val_dataset             # evaluation dataset\r\n",
        ")\r\n",
        "\r\n",
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zifO_SAbGUP1"
      },
      "source": [
        "from transformers import TFDistilBertForSequenceClassification\r\n",
        "model = TFDistilBertForSequenceClassification(config=config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DezfX9COoXXK",
        "outputId": "bd70d054-abf9-4045-a20d-0b33ae69e1b2"
      },
      "source": [
        "## Model training with Keras API\r\n",
        "\r\n",
        "\r\n",
        "model.compile(optimizer=optimizer, loss=model.compute_loss, metrics=['accuracy']) # can also use any keras loss fn\r\n",
        "model.fit(train_dataset.shuffle(1000).batch(16), epochs=4, batch_size=16)\r\n",
        "\r\n",
        "# model.save_weights('./my_model.h5')\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "1321/1321 [==============================] - 1301s 980ms/step - loss: 0.0759 - accuracy: 0.9704\n",
            "Epoch 2/4\n",
            "1321/1321 [==============================] - 1294s 979ms/step - loss: 0.3311 - accuracy: 0.9265\n",
            "Epoch 3/4\n",
            "1321/1321 [==============================] - 1290s 976ms/step - loss: 0.3170 - accuracy: 0.9287\n",
            "Epoch 4/4\n",
            "1321/1321 [==============================] - 1290s 977ms/step - loss: 0.3646 - accuracy: 0.9132\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3vRKljSDJOx"
      },
      "source": [
        "model.load_weights('./my_model.h5')\r\n",
        "model.compile(optimizer=optimizer, loss=model.compute_loss, metrics=['accuracy']) # can also use any keras loss fn\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "nhjyKvTNjcap",
        "outputId": "a81cb857-9a7f-4a65-fcea-da558a92b74c"
      },
      "source": [
        "print(model.compute_loss())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-29e97260680b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: compute_loss() missing 2 required positional arguments: 'labels' and 'logits'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uo5Zd__sfKzS",
        "outputId": "27380920-87a1-4038-8438-508412b85a48"
      },
      "source": [
        "model.save_weights('./my_model.h5')\r\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "aclImdb  aclImdb_v1.tar.gz  logs  my_model.h5  runs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrA7y1sh5fVK"
      },
      "source": [
        "# import torch\r\n",
        "\r\n",
        "# class IMDbDataset(torch.utils.data.Dataset):\r\n",
        "#     def __init__(self, encodings, labels):\r\n",
        "#         self.encodings = encodings\r\n",
        "#         self.labels = labels\r\n",
        "\r\n",
        "#     def __getitem__(self, idx):\r\n",
        "#         item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\r\n",
        "#         item['labels'] = torch.tensor(self.labels[idx])\r\n",
        "#         return item\r\n",
        "\r\n",
        "#     def __len__(self):\r\n",
        "#         return len(self.labels)\r\n",
        "\r\n",
        "# train_dataset = IMDbDataset(train_encodings, train_labels)\r\n",
        "# val_dataset = IMDbDataset(val_encodings, val_labels)\r\n",
        "# test_dataset = IMDbDataset(test_encodings, test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1l4OPVfu48vo"
      },
      "source": [
        "# from transformers import DistilBertForSequenceClassification, Trainer, TrainingArguments\r\n",
        "\r\n",
        "# training_args = TrainingArguments(\r\n",
        "#     output_dir='./results',          # output directory\r\n",
        "#     num_train_epochs=3,              # total number of training epochs\r\n",
        "#     per_device_train_batch_size=16,  # batch size per device during training\r\n",
        "#     per_device_eval_batch_size=16,   # batch size for evaluation\r\n",
        "#     warmup_steps=500,                # number of warmup steps for learning rate scheduler\r\n",
        "#     weight_decay=0.01,               # strength of weight decay\r\n",
        "#     logging_dir='./logs',            # directory for storing logs\r\n",
        "#     logging_steps=10,\r\n",
        "#     learning_rate=1e-5\r\n",
        "# )\r\n",
        "\r\n",
        "# model = DistilBertForSequenceClassification(config=pretrained.config)\r\n",
        "\r\n",
        "# trainer = Trainer(\r\n",
        "#     model=model,                         # the instantiated 🤗 Transformers model to be trained\r\n",
        "#     args=training_args,                  # training arguments, defined above\r\n",
        "#     train_dataset=train_dataset,         # training dataset\r\n",
        "#     eval_dataset=val_dataset            \r\n",
        "# )\r\n",
        "\r\n",
        "# trainer.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKVHC9-kLfwh"
      },
      "source": [
        "# for batch in val_dataset:\r\n",
        "#   print(batch.keys())\r\n",
        "#   print(batch['input_ids'].shape)\r\n",
        "#   print(batch['attention_mask'].shape)\r\n",
        "#   print(model(input_ids=torch.tensor(batch['input_ids'].unsqueeze(dim=1).cuda()\r\n",
        "# ), attention_mask=torch.tensor(batch['attention_mask'].unsqueeze(dim=1)).cuda()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-SIVyBSuRIj"
      },
      "source": [
        "# model = DistilBertForSequenceClassification(config=config)\r\n",
        "# print(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpxcvDIAZW5M"
      },
      "source": [
        "# from transformers import DataCollatorForLanguageModeling\r\n",
        "\r\n",
        "# data_collator = DataCollatorForLanguageModeling(\r\n",
        "#     tokenizer=tokenizer, mlm=True, mlm_probability=0.15\r\n",
        "# )\r\n",
        "# data_collator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmDDqy6Ds-RD"
      },
      "source": [
        "# from transformers import Trainer, TrainingArguments\r\n",
        "\r\n",
        "# training_args = TrainingArguments(\r\n",
        "#     output_dir=\"./dbert_scratch\",\r\n",
        "#     overwrite_output_dir=True,\r\n",
        "#     num_train_epochs=5,\r\n",
        "#     per_gpu_train_batch_size=64,\r\n",
        "#     save_steps=10_000,\r\n",
        "#     save_total_limit=2,\r\n",
        "#     learning_rate=1e-3\r\n",
        "# )\r\n",
        "\r\n",
        "# trainer = Trainer(\r\n",
        "#     model=model,\r\n",
        "#     args=training_args,\r\n",
        "#     data_collator=data_collator,\r\n",
        "#     train_dataset=dataset['train'],\r\n",
        "#     eval_dataset=dataset['test']\r\n",
        "# )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgH9M-3wxINW",
        "outputId": "346a8dae-d4b3-4704-e687-dcbd2e4a45c9"
      },
      "source": [
        "# dataset['train']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text', 'label'],\n",
              "    num_rows: 25000\n",
              "})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVpPMq2AtijJ"
      },
      "source": [
        "# trainer.save_model(\"./dbert_scratch\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdLo5VA3JVJ1",
        "outputId": "c1fae0a5-aed2-4b59-a349-b6e3ab8d8fea"
      },
      "source": [
        "# from transformers import pipeline\r\n",
        "\r\n",
        "# fill_mask = pipeline(\r\n",
        "#     \"fill-mask\",\r\n",
        "#     model=\"./dbert_scratch\",\r\n",
        "#     tokenizer=tokenizer\r\n",
        "# )\r\n",
        "# fill_mask(\"This movie was pretty [MASK].\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at ./dbert_scratch were not used when initializing DistilBertForMaskedLM: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
            "- This IS expected if you are initializing DistilBertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForMaskedLM were not initialized from the model checkpoint at ./dbert_scratch and are newly initialized: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.0002560511347837746,\n",
              "  'sequence': 'this movie was pretty peers.',\n",
              "  'token': 12746,\n",
              "  'token_str': 'peers'},\n",
              " {'score': 0.00024439391563646495,\n",
              "  'sequence': 'this movie was pretty scotland.',\n",
              "  'token': 3885,\n",
              "  'token_str': 'scotland'},\n",
              " {'score': 0.00023974172654561698,\n",
              "  'sequence': 'this movie was pretty [unused911].',\n",
              "  'token': 916,\n",
              "  'token_str': '[unused911]'},\n",
              " {'score': 0.00020217549172230065,\n",
              "  'sequence': 'this movie was pretty adventist.',\n",
              "  'token': 25696,\n",
              "  'token_str': 'adventist'},\n",
              " {'score': 0.0001996046194108203,\n",
              "  'sequence': 'this movie was pretty clip.',\n",
              "  'token': 12528,\n",
              "  'token_str': 'clip'}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6P22EN9TjJ-"
      },
      "source": [
        "### 2.2 Evaluate your model and the fine-tuned model on IMDB [11 points]\n",
        "\n",
        "**Tip**: You might find [`TextClassificationPipeline`](https://huggingface.co/transformers/main_classes/pipelines.html#transformers.TextClassificationPipeline) helpful. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nDS-BcTTwLa"
      },
      "source": [
        "#### a. (1 point) Randomly sample 1000 examples from the test split."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgAjHMRYp7EI"
      },
      "source": [
        "SEED = 42\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yz7GCUwVrPiT",
        "outputId": "cfaa12b3-ad4d-4320-96f8-1f89601c5cf9"
      },
      "source": [
        "type(test_encodings)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "transformers.tokenization_utils_base.BatchEncoding"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFkwDIRTuFHY",
        "outputId": "514f7d42-4cb1-425f-807b-466ccb66c94b"
      },
      "source": [
        "################## YOUR CODE HERE ##################\n",
        "num_test = len(test_texts)\n",
        "print(f'Test set size: {num_test}')\n",
        "chosen = np.random.choice(np.arange(num_test), 1000, replace=False)\n",
        "print(chosen.shape)\n",
        "\n",
        "sampled_text = [test_texts[idx] for idx in chosen]\n",
        "print(f'Number sampled: {len(sampled_text)}')\n",
        "sampled_enc = tokenizer(sampled_text, truncation=True, padding=True)\n",
        "\n",
        "## truncate samples for feeding into model\n",
        "\n",
        "trunc = [' '.join(nltk.tokenize.word_tokenize(sent)[:512]) for sent in sampled_text]\n",
        "####################################################"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test set size: 25000\n",
            "(1000,)\n",
            "Number sampled: 1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "id": "XSamKeTb1KIp",
        "outputId": "fc4661d4-ef3c-4648-db2f-bf7b74a2f710"
      },
      "source": [
        "trunc[10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Story about a widowed father ( Claude Rains ) bringing up his four daughters . Emma ( Gale Page ) is loved by big hunky Ernest ( Dick Foran ) . Thea ( Lola Lane ) is romanced by an old but wealthy man . Kay ( Rosemary Lane ) wants to become a singer . Ann ( Priscilla Lane ) is a romantic . Drop dead handsome Felix Deitz ( Jeffrey Lynn ) , a business associate of their father , comes to stay with them . All the sisters fall in love with him . Then tough cynical Mickey ( John Garfield ) enters the picture ... < br / > < br / > Very entertaining movie was a big hit and nominated for five Academy Awards . It 's beautifully directed by Michael Curitz , has a pretty good ( if predictable ) script and a VERY attractive cast ( especially Lynn ) . Also this was John Garfield 's first film and made him a star . This was so popular there were three or four sequels ( which I never saw ) . This is an engrossing , entertaining , big budget soap opera -- well worth seeing .\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qn52SvAtUEuM"
      },
      "source": [
        "#### b. (2 points) Use **your model** to make predictions on these examples and output predicted labels and associated probabilities."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGdLYIc_uI_y"
      },
      "source": [
        "################## YOUR CODE HERE ##################\n",
        "\n",
        "\n",
        "\n",
        "####################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VoUktT5dUIZX"
      },
      "source": [
        "#### c. (2 points) Evaluate and report **your model’s** performance on these 1000 examples using the metric specified in 1.2 (c)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8goGh3NuX9C"
      },
      "source": [
        "################## YOUR CODE HERE ##################\n",
        "\n",
        "####################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfZWs-XivKvP"
      },
      "source": [
        "**Answer**:\n",
        "\n",
        "[YOUR ANSWER HERE]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jgkP9ZYUS_i"
      },
      "source": [
        "#### d. (2 points) Use the **fine-tuned model** to make predictions on these examples and output predicted labels and associated probabilities.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "czc90w5Au2H-",
        "outputId": "5b84a600-6fa9-45bc-cbaf-4d5492badeea"
      },
      "source": [
        "################## YOUR CODE HERE ##################\n",
        "# nlp = pipeline(...)\n",
        "\n",
        "pretrained = AutoModelForSequenceClassification.from_pretrained(\"textattack/distilbert-base-uncased-imdb\")\n",
        "\n",
        "\n",
        "from transformers import pipeline, TextClassificationPipeline\n",
        "\n",
        "nlp = pipeline('sentiment-analysis', \n",
        "               model=pretrained, \n",
        "               tokenizer=tokenizer)\n",
        "\n",
        "\n",
        "ret = nlp([\"hey this movie was pretty good\", 'nah movie terrible', 'movie was ok'])\n",
        "ret\n",
        "####################################################"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-66627532ee63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m nlp = pipeline('sentiment-analysis', \n\u001b[1;32m     10\u001b[0m                \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                tokenizer=tokenizer)\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUtBAbLzwzBL"
      },
      "source": [
        "### Predicted labels and probabilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frYQdw69xmF3",
        "outputId": "30a5bdf9-847a-48d3-98e6-92b9965f7b46"
      },
      "source": [
        "len(sampled_enc['input_ids'][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "512"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "id": "1HmCEq2VwgZ0",
        "outputId": "a4302f0c-6520-4360-f72c-b04dcf3b948f"
      },
      "source": [
        "results_pretrained = nlp(sampled_text)\r\n",
        "len(results_pretrained)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-feac26e87c11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults_pretrained\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampled_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_pretrained\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'nlp' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vx-NL91yUWwQ"
      },
      "source": [
        "#### e. (2 points) Evaluate and report the **fine-tuned model’s** performance on these 1000 examples using the metric specified in 1.2 (c)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKCo4005ut0b"
      },
      "source": [
        "################## YOUR CODE HERE ##################\n",
        "# Run inference on the sampled examples\n",
        "# - https://huggingface.co/transformers/main_classes/pipelines.html\n",
        "\n",
        "# Compute the metrics on your examples\n",
        "# - https://huggingface.co/docs/datasets/using_metrics.html\n",
        "\n",
        "####################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pu0seYLzvO2t"
      },
      "source": [
        "**Answer**:\n",
        "\n",
        "[YOUR ANSWER HERE]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqSco5E9UedJ"
      },
      "source": [
        "#### f. (2 points) Compare the performance of the model trained from scratch and the fine-tuned model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1u4I8yPfvQQL"
      },
      "source": [
        "**Answer**:\n",
        "\n",
        "[YOUR ANSWER HERE]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcaAxk0BUsZt"
      },
      "source": [
        "### 2.3 Error analysis of the fine-tuned model [10 points]\n",
        "\n",
        "Next, do error analysis on the examples that the fine-tuned model failed to predict correctly. This is a common debugging step where buckets of errors are identified to inform how the model might be improved."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JCrBltvUxpF"
      },
      "source": [
        "#### a. (1 points) Pull out the examples that your fine-tuned model made errors on. Examine multiple examples to see if you can spot a pattern.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltEfFg_qv1HL"
      },
      "source": [
        "################## YOUR CODE HERE ##################\n",
        "\n",
        "####################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4zT0lt0U4g6"
      },
      "source": [
        "#### b. (3 points) Identify at least 1 pattern that you believe your model is missing. Include at least 3 examples from the data that support your hypothesis.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RxO_nQmFv86A"
      },
      "source": [
        "**Answer**:\n",
        "\n",
        "[YOUR ANSWER HERE]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFHthaqvU8fT"
      },
      "source": [
        "#### c. (2 points) Explain why these examples might have been difficult for the fine-tuned model to correctly make predictions on."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_Xsu687v-oy"
      },
      "source": [
        "**Answer**:\n",
        "\n",
        "[YOUR ANSWER HERE]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzLQvzyiU_xN"
      },
      "source": [
        "#### d. (2 points) Manually create 3 examples that conform to the pattern you observed, and run inference on them using the model. What did you find?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFldA0lzwB0E"
      },
      "source": [
        "################## YOUR CODE HERE ##################\n",
        "# Inference on your own examples\n",
        "####################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ao21-dAFwANW"
      },
      "source": [
        "**Answer**:\n",
        "\n",
        "[YOUR ANSWER HERE]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxaviDJkVF7F"
      },
      "source": [
        "#### e. (2 points) Suggest what steps we might take to address this error bucket.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0_n5JC1wEu2"
      },
      "source": [
        "**Answer**:\n",
        "\n",
        "[YOUR ANSWER HERE]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JulVmjPVK7g"
      },
      "source": [
        "### 2.4 Pertubation Analysis [10 points]\n",
        "\n",
        "Inputs, especially inputs by users, might contain a lot of noise (e.g. misspelling, repeated chaaaaaaaaracter, missing punctuation, etc.). You want to see how well your models perform on input with noises."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrS6IzqqV2E8"
      },
      "source": [
        "#### a. (2 points) Write a function to randomly add noise to an input while preserving its label. Here are some ideas to consider (you can combine them too, e.g. 10% of the time do this, 20% of the time do this):\n",
        "\n",
        "- Randomly remove a character\n",
        "- Randomly repeat a character or a phrase\n",
        "- Replace a word with a similar word \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7pfxmyCwLKI"
      },
      "source": [
        "################## YOUR CODE HERE ##################\n",
        "# def add_random_noice(sentence):\n",
        "# \n",
        "####################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHGaFeHtZpjL"
      },
      "source": [
        "#### b. (1 point) Apply this function to 500 samples in your test split.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eLL4WbNwUVD"
      },
      "source": [
        "################## YOUR CODE HERE ##################\n",
        "\n",
        "####################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10TRENSZZvBJ"
      },
      "source": [
        "#### c. (2 points) Use your model to make predictions on these noisy examples and output predicted labels and associated probabilities."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26ELRKp9wWFa"
      },
      "source": [
        "################## YOUR CODE HERE ##################\n",
        "\n",
        "####################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXfxdn4EZyEm"
      },
      "source": [
        "#### d. (1 point) Evaluate your model’s performance on these noisy examples using the metric specified in 1.2 (c)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkVIpV_RwXKm"
      },
      "source": [
        "################## YOUR CODE HERE ##################\n",
        "\n",
        "####################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiA0Iv3vZ1dw"
      },
      "source": [
        "#### e. (2 points) Use the fine-tuned model to make predictions on these noisy examples and output predicted labels and associated probabilities."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Q3R40pHwZqn"
      },
      "source": [
        "################## YOUR CODE HERE ##################\n",
        "\n",
        "####################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ti5yTl7AZ5iP"
      },
      "source": [
        "#### f. (1 point) Evaluate the fine-tuned model’s performance on these noisy examples using the metric specified in 1.2 (c)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojBDjlIGwaTW"
      },
      "source": [
        "################## YOUR CODE HERE ##################\n",
        "\n",
        "####################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sY4pGgtSZ-bW"
      },
      "source": [
        "#### g. (1 point) Compare the performance of your model and the fine-tuned model on these noisy samples.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGTuTq5Lwbxi"
      },
      "source": [
        "**Answer:**\n",
        "\n",
        "[YOUR ANSWER HERE]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pCEHok3ant4"
      },
      "source": [
        "### 2.5 Slice-based analysis [10 points]\n",
        "\n",
        "We’ve been evaluating both models on a coarse-grained metric. Let’s take a deeper look into how we can evaluate them on different slices.\n",
        "\n",
        "Play around with the test split of IMDB -- slice it into different subgroups. Some ideas for slicing your test split:\n",
        "\n",
        "- By **input lengths** (e.g. maybe your model will perform well on inputs of less than 10 characters but horribly for inputs of more than 1000 characters).\n",
        "- By **movie names** (can you figure out how to extract movie names from reviews?).\n",
        "- By **the number of punctuations** in each review.\n",
        "- etc. Play around with your data!\n",
        "\n",
        "Choose two slices of data on which your model’s performances are non-trivially different. Each slice should have at least 100 samples.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeNj67wbbZF0"
      },
      "source": [
        "# Cell for you to play around with your data. (not graded)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWFhVdGQbesS"
      },
      "source": [
        "#### a. (5 points) Describe your reason for choosing these two slices. Explain why the model might perform differently on them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KI8pIAEDwifS"
      },
      "source": [
        "**Answer:**\n",
        "\n",
        "[YOUR ANSWER HERE]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acmwnDNHbr7F"
      },
      "source": [
        "#### b. (2 points) Write code to extract these two slices from your test split.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxRigg0pb5Oe"
      },
      "source": [
        "################## YOUR CODE HERE ##################\n",
        "\n",
        "####################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fd9zedcebtua"
      },
      "source": [
        "#### c. (1 point) Write code to report each slice’s statistics. Report the statistics. \n",
        "1. Slice size\n",
        "2. Label distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOKkjjxwb2U4"
      },
      "source": [
        "################## YOUR CODE HERE ##################\n",
        "\n",
        "####################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrQToE2iwth6"
      },
      "source": [
        "**Answer:**\n",
        "\n",
        "[YOUR ANSWER HERE]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2M6sOvGbk36"
      },
      "source": [
        "#### d. (1 point) Write code to evaluate **your model** performance on these two slices, including the metric specified in 1.2 (c) and the confusion matrix.\n",
        "- [sklearn.metrics.confusion_matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html) may be useful here\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnfK8eHncCI8"
      },
      "source": [
        "################## YOUR CODE HERE ##################\n",
        "\n",
        "####################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WT22WTCBcENu"
      },
      "source": [
        "#### e. (1 point) Write code to evaluate the **fine-tuned model** performance on these two slices, including the metric specified in 1.2 (c) and the confusion matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R91RMWmCcHcB"
      },
      "source": [
        "################## YOUR CODE HERE ##################\n",
        "\n",
        "####################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lpQD5EicG7c"
      },
      "source": [
        "## Problem 3. In-Distribution v.s. Out-of-Distribution\n",
        "\n",
        "In problem 2, when we evaluate the fine-tuned model on the test split that comes from the same distribution the model was fine-tuned on. In this problem, we’ll evaluate the fine-tuned model’s performance on an out-of-distribution test set.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjR-QhBZdS6P"
      },
      "source": [
        "### 3.1 Evaluate the fine-tuned model on an out-of-distribution task [4 points]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0thRp1bdWSS"
      },
      "source": [
        "#### a. (1 point) If the dataset has a test split, randomly sample 500 examples from the test split. If it doesn’t have a test split, randomly sample 500 samples from the entire dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3V1dRlPtw_ZN"
      },
      "source": [
        "################## YOUR CODE HERE ##################\n",
        "\n",
        "####################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROwapfEHdbeD"
      },
      "source": [
        "#### b. (1 point) Use the fine-tuned model to make predictions on these examples and output predicted labels and associated probabilities.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSu3vZKaxDOe"
      },
      "source": [
        "################## YOUR CODE HERE ##################\n",
        "\n",
        "####################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFoXo2H5dcKH"
      },
      "source": [
        "#### c. (1 point) Evaluate the fine-tuned model’s performance on these 500 examples using the metric specified in 1.2 (c).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzGTemcVxET-"
      },
      "source": [
        "################## YOUR CODE HERE ##################\n",
        "\n",
        "####################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmYgBCYVdfa3"
      },
      "source": [
        "#### d. (1 point) Compare the performance of the fine-tuned model on IMDB and this dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvgAUhuGxIlO"
      },
      "source": [
        "**Answer:**\n",
        "\n",
        "[YOUR ANSWER HERE]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iW21TCOodqRb"
      },
      "source": [
        "### 3.2 Error analysis of the fine-tuned model on out-of-distribution task\n",
        "\n",
        "Next, do error analysis on the examples that the fine-tuned model failed to predict correctly. This is a common debugging step where buckets of errors are identified to inform how the model might be improved.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dO3_CEUd0F4"
      },
      "source": [
        "#### a. (1 point) Pull out the examples that your fine-tuned model made errors on.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Oe6-B0wxczb"
      },
      "source": [
        "################## YOUR CODE HERE ##################\n",
        "\n",
        "####################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uouC3NjGd2vI"
      },
      "source": [
        "#### b. (3 points) Identify at least 1 pattern that you believe your model is missing. Include at least 3 examples from the data that support your hypothesis.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItAj4tXSxfpt"
      },
      "source": [
        "**Answer:**\n",
        "\n",
        "[YOUR ANSWER HERE]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nl9eJgFQd4cW"
      },
      "source": [
        "#### c. (2 points) Explain why these examples might have been difficult for the fine-tuned model to correctly make predictions on.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJcUOKPZxgk2"
      },
      "source": [
        "**Answer:**\n",
        "\n",
        "[YOUR ANSWER HERE]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBnlT6uLd6YW"
      },
      "source": [
        "#### d. (2 points) Manually write down 3 examples that conform to the pattern you observed, and run inference on them using the model. What did you find?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEVDg354xmOo"
      },
      "source": [
        "################## YOUR CODE HERE ##################\n",
        "# Inference on your own examples\n",
        "####################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRwEgbQNxhRI"
      },
      "source": [
        "**Answer:**\n",
        "\n",
        "[YOUR ANSWER HERE]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_8Fh9steQAU"
      },
      "source": [
        "#### e. (2 points) Suggest what steps we might take to address this error bucket.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwS8jntsxwZ5"
      },
      "source": [
        "**Answer:**\n",
        "\n",
        "[YOUR ANSWER HERE]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NQRHGXceRzU"
      },
      "source": [
        "### 3.3 Calibration [4 points]\n",
        "You will examine whether the fine-tuned model is calibrated. You might want to look into [sklearn.calibration.calibration_curve](https://scikit-learn.org/stable/modules/generated/sklearn.calibration.calibration_curve.html).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uhO5ncZetR3"
      },
      "source": [
        "#### a. (1 point) Compute the average calibration error of the fine-tuned model on IMDB.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zr4_iyZvyFuj"
      },
      "source": [
        "################## YOUR CODE HERE ##################\n",
        "\n",
        "####################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3T7_YVhevT4"
      },
      "source": [
        "#### b. (1 point) Compute the average calibration error of the fine-tuned model on the out-of-distribution dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sQ5SW10yHv5"
      },
      "source": [
        "################## YOUR CODE HERE ##################\n",
        "\n",
        "####################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g41sOEMfexi7"
      },
      "source": [
        "#### c. (2 points) Plot the calibration curves for the fine-tuned model on both datasets.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2D-dHNZyJYj"
      },
      "source": [
        "################## YOUR CODE HERE ##################\n",
        "\n",
        "####################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjYcVsIyyMTV"
      },
      "source": [
        "**Answer:**\n",
        "\n",
        "[YOUR ANSWER HERE]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIEN2eFHfL5p"
      },
      "source": [
        "## Problem 4. Multilabel Tasks [7 points]\n",
        "\n",
        "Now we’ll be using our understanding of pretrained models and fine-tuned models to try to get good performance on a difficult dataset.\n",
        "\n",
        "Choose one of the following multilabel tasks:\n",
        "- Circa dataset: https://huggingface.co/datasets/circa \n",
        "- PUBHEALTH dataset: https://huggingface.co/datasets/health_fact\n",
        "- GoEmotions dataset: https://huggingface.co/datasets/go_emotions\n",
        "\n",
        "**Tip:** read the paper associated with each dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xcifhdl7fZhD"
      },
      "source": [
        "#### a. (2 points) Describe the train/test split distributions, the dataset’s columns, and their statistics.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXffBPHJySW5"
      },
      "source": [
        "**Answer:**\n",
        "\n",
        "[YOUR ANSWER HERE]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZ0fa9nYfa3q"
      },
      "source": [
        "#### b. (1 point) Plot its label distribution as a bar graph, with the labels on the x-axis and number of examples for each labels on the y-axis.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHSNImviyWaR"
      },
      "source": [
        "################## YOUR CODE HERE ##################\n",
        "# See https://matplotlib.org/3.3.3/api/_as_gen/matplotlib.pyplot.bar.html\n",
        "####################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfK77Q5PyS28"
      },
      "source": [
        "**Answer:**\n",
        "\n",
        "[YOUR ANSWER HERE]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQulicAaftcC"
      },
      "source": [
        "#### c. (2 points) What metric(s) would be appropriate for this dataset? Why?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMq7z3RxyUiy"
      },
      "source": [
        "**Answer:**\n",
        "\n",
        "[YOUR ANSWER HERE]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XY4u1i8PfwHi"
      },
      "source": [
        "#### d. (2 points) Explain why you might think that this dataset is hard.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMIPdOAlyhQF"
      },
      "source": [
        "**Answer:**\n",
        "\n",
        "[YOUR ANSWER HERE]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BoWO3c5afzE6"
      },
      "source": [
        "# Part II. OpenAI API [7 points + 3 bonus points]\n",
        "\n",
        "In this part, you will play around with the [OpenAI API](https://beta.openai.com/). You should have received emails about accessing the OpenAI API by now. Please let us know if you haven’t.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ly0BMYdMgWXT"
      },
      "source": [
        "## Problem 5. English to Bash [4 points]\n",
        "\n",
        "Open [Playground](https://beta.openai.com/playground). In **`Load a preset...`**, select **`Text to command`**. \n",
        "\n",
        "Copy in the following prompt: \n",
        "\n",
        "```\n",
        "Q: List files\n",
        "A: ls -l\n",
        "Q: Count files in a directory\n",
        "A: ls -l | wc -l\n",
        "Q: Disk space used by home directory\n",
        "A: du ~\n",
        "Q: Replace foo with bar in all .py files\n",
        "A: sed -i .bak -- 's/foo/bar/g' *.py\n",
        "Q: Delete the models subdirectory\n",
        "A: rm -rf ./models\n",
        "Q: Firewall all incoming connections to port 22 on this machine.\n",
        "A: iptables -A INPUT -p tcp --dport 22 -j DROP\n",
        "Q:\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYhS8b80gex3"
      },
      "source": [
        "#### a. (2 point) Write a English sentence that makes the API output the bash command `ls *.py`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oX_Qu0NrxNpG"
      },
      "source": [
        "**Answer:**\n",
        "\n",
        "[YOUR ANSWER HERE]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BrppISFg2jo"
      },
      "source": [
        "#### b. (3 points) Come up with a bash command and a corresponding English explanation of the command (imagine that you’re helping a friend navigate the terminal, and you are instructing them what to do). Run the English sentence in the Playground and observe the command that you obtain. Is it the same as the bash command you had in mind? Why or why not? Play around with some longer bash commands: can you successfully generate long or complex bash commands from english explanations?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AY7EUR_xNOn"
      },
      "source": [
        "**Answer:**\n",
        "\n",
        "[YOUR ANSWER HERE]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZQjx-1ThOnt"
      },
      "source": [
        "### Problem 6. Improving English [2 points + 3 bonus points]\n",
        "\n",
        "In [Playground](https://beta.openai.com/playground). In **`Load a preset...`**, select **`Grammatical Standard English`**. You will see the following prompt:\n",
        "\n",
        "```\n",
        "Non-standard English: Please provide me with a short brief of the design you’re looking for and that’d be nice if you could share some examples or project you did before.\n",
        "Standard American English: Please provide me with a short brief of the design you’re looking for and some examples or previous projects you’ve done would be helpful.\n",
        " \n",
        "Non-standard English: If I’m stressed out about something, I tend to have problem to fall asleep.\n",
        "Standard American English: If I’m stressed out about something, I tend to have a problem falling asleep.\n",
        " \n",
        "Non-standard English: There is plenty of fun things to do in the summer when your able to go outside.\n",
        "Standard American English: There are plenty of fun things to do in the summer when you are able to go outside.\n",
        " \n",
        "Non-standard English: She no went to the market.\n",
        "Standard American English: She didn't go to the market.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iskCGMBUhgZ8"
      },
      "source": [
        "#### a. (2 points) Write a bad non-standard English sentence. Report the Non-standard English you have input, and the output obtained from the API. Did the API fix it?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wskxOe5LxM00"
      },
      "source": [
        "**Answer:**\n",
        "\n",
        "[YOUR ANSWER HERE]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYq9e35vhrdF"
      },
      "source": [
        "#### b. (3 bonus points) Come up with a bad Enligsh sentence that the API cannot fix. Report the Non-standard English you have input, and the output obtained from the API."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8atUxWsuxMZC"
      },
      "source": [
        "**Answer:**\n",
        "\n",
        "[YOUR ANSWER HERE]"
      ]
    }
  ]
}